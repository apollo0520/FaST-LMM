{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0674b5a82d3625dac09d19ce7b99b58a4cbb63b107b610ea8d52cf658445d1e25",
   "display_name": "Python 3.8.5 64-bit ('gtg': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from fastlmm.association import single_snp\n",
    "from pysnptools.util.mapreduce1.runner import Local, LocalMultiProc\n",
    "from pysnptools.snpreader import Bed, Pheno, SnpData\n",
    "from fastlmm.feature_selection.test import TestFeatureSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedbase = '../../fastlmm/feature_selection/examples/toydata.5chrom.bed'\n",
    "phen_fn = '../../fastlmm/feature_selection/examples/toydata.phe'\n",
    "cov_fn = '../../fastlmm/feature_selection/examples/toydata.cov'\n",
    "assert Path(phen_fn).exists()\n",
    "\n",
    "tempout_dir = \"tempout/single_snp\"\n",
    "os.makedirs(tempout_dir,exist_ok=True)\n",
    "\n",
    "def file_name(testcase_name):\n",
    "    temp_fn = os.path.join(tempout_dir,testcase_name+\".txt\")\n",
    "    if os.path.exists(temp_fn):\n",
    "        os.remove(temp_fn)\n",
    "    return temp_fn\n",
    "\n",
    "\n",
    "def compare_files(frame,ref_base):\n",
    "    reffile = TestFeatureSelection.reference_file(\"single_snp/\"+ref_base+\".txt\")\n",
    "    assert Path(reffile).exists()\n",
    "\n",
    "    #sid_list,pvalue_list = frame['SNP'].values,frame['Pvalue'].values\n",
    "\n",
    "    #sid_to_pvalue = {}\n",
    "    #for index, sid in enumerate(sid_list):\n",
    "    #    sid_to_pvalue[sid] = pvalue_list[index]\n",
    "\n",
    "    reference=pd.read_csv(reffile,delimiter='\\s',comment=None,engine='python')\n",
    "    assert len(frame) == len(reference), f\"# of rows ({len(frame)} vs {len(reference)}) differs from file '{reffile}'\"\n",
    "    for _, row in reference.iterrows():\n",
    "        sid = row.SNP\n",
    "        pvalue = frame[frame['SNP'] == sid].iloc[0].PValue\n",
    "        diff = abs(row.PValue - pvalue)\n",
    "        if diff > 1e-5 or np.isnan(diff):\n",
    "            raise Exception(\"pair {0} differs too much from file '{1}'\".format(sid,reffile))\n",
    "        assert abs(row.PValue - pvalue) < 1e-5, \"wrong\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TestSingleSnpLeaveOutOneChrom test_multipheno\n",
      "Loading fam file ..\\..\\fastlmm\\feature_selection\\examples\\toydata.5chrom.fam\n",
      "Loading bim file ..\\..\\fastlmm\\feature_selection\\examples\\toydata.5chrom.bim\n",
      "(500, 10000)\n",
      "Setting GB_goal to 0.1446951289176941 GB\n",
      "Starting '_read_with_standardizing'\n",
      "reading 715 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.14177116]\n",
      "Starting '_read_with_standardizing'\n",
      "reading 715 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.]\n",
      "cmk\n",
      "time=0.04199719429016113\n",
      "Setting GB_goal to 0.1446951289176941 GB\n",
      "Starting '_read_with_standardizing'\n",
      "reading 638 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.03043305]\n",
      "Starting '_read_with_standardizing'\n",
      "reading 638 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.]\n",
      "cmk\n",
      "time=0.04500269889831543\n",
      "Setting GB_goal to 0.1446951289176941 GB\n",
      "Starting '_read_with_standardizing'\n",
      "reading 790 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.01831809]\n",
      "Starting '_read_with_standardizing'\n",
      "reading 790 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.]\n",
      "cmk\n",
      "time=0.031998634338378906\n",
      "Setting GB_goal to 0.1446951289176941 GB\n",
      "Starting '_read_with_standardizing'\n",
      "reading 901 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.04246161]\n",
      "Starting '_read_with_standardizing'\n",
      "reading 901 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.]\n",
      "cmk\n",
      "time=0.03499722480773926\n",
      "Setting GB_goal to 0.1446951289176941 GB\n",
      "Starting '_read_with_standardizing'\n",
      "reading 956 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.02198921]\n",
      "Starting '_read_with_standardizing'\n",
      "reading 956 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.]\n",
      "cmk\n",
      "time=0.02900075912475586\n",
      "PhenotypeName\tpheno1\n",
      "SampleSize\t500\n",
      "SNPCount\t1000\n",
      "Runtime\t1.0484404563903809\n",
      "Setting GB_goal to 0.1446951289176941 GB\n",
      "Starting '_read_with_standardizing'\n",
      "reading 715 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.14177116]\n",
      "Starting '_read_with_standardizing'\n",
      "reading 715 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.14177116]\n",
      "cmk\n",
      "time=0.05800127983093262\n",
      "Setting GB_goal to 0.1446951289176941 GB\n",
      "Starting '_read_with_standardizing'\n",
      "reading 638 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.03043305]\n",
      "Starting '_read_with_standardizing'\n",
      "reading 638 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.03043305]\n",
      "cmk\n",
      "time=0.05195498466491699\n",
      "Setting GB_goal to 0.1446951289176941 GB\n",
      "Starting '_read_with_standardizing'\n",
      "reading 790 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.01831809]\n",
      "Starting '_read_with_standardizing'\n",
      "reading 790 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.01831809]\n",
      "cmk\n",
      "time=0.047998666763305664\n",
      "Setting GB_goal to 0.1446951289176941 GB\n",
      "Starting '_read_with_standardizing'\n",
      "reading 901 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.04246161]\n",
      "Starting '_read_with_standardizing'\n",
      "reading 901 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.03 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.04246161]\n",
      "cmk\n",
      "time=0.03300166130065918\n",
      "Setting GB_goal to 0.1446951289176941 GB\n",
      "Starting '_read_with_standardizing'\n",
      "reading 956 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.03 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.02198921]\n",
      "Starting '_read_with_standardizing'\n",
      "reading 956 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.03 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.02198921]\n",
      "cmk\n",
      "time=0.03500008583068848\n",
      "PhenotypeName\tpheno1a\n",
      "SampleSize\t500\n",
      "SNPCount\t1000\n",
      "Runtime\t1.245448112487793\n",
      "Setting GB_goal to 0.1446951289176941 GB\n",
      "Starting '_read_with_standardizing'\n",
      "reading 715 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.14177116]\n",
      "time=0.02500176429748535\n",
      "Setting GB_goal to 0.1446951289176941 GB\n",
      "Starting '_read_with_standardizing'\n",
      "reading 638 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.03043305]\n",
      "time=0.030000686645507812\n",
      "Setting GB_goal to 0.1446951289176941 GB\n",
      "Starting '_read_with_standardizing'\n",
      "reading 790 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.01831809]\n",
      "time=0.017998695373535156\n",
      "Setting GB_goal to 0.1446951289176941 GB\n",
      "Starting '_read_with_standardizing'\n",
      "reading 901 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.04246161]\n",
      "time=0.020996809005737305\n",
      "Setting GB_goal to 0.1446951289176941 GB\n",
      "Starting '_read_with_standardizing'\n",
      "reading 956 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.02198921]\n",
      "time=0.016998291015625\n",
      "PhenotypeName\tpheno0\n",
      "SampleSize\t500\n",
      "SNPCount\t1000\n",
      "Runtime\t0.7589511871337891\n",
      "Setting GB_goal to 0.1446951289176941 GB\n",
      "Starting '_read_with_standardizing'\n",
      "reading 715 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.]\n",
      "time=0.02900099754333496\n",
      "Setting GB_goal to 0.1446951289176941 GB\n",
      "Starting '_read_with_standardizing'\n",
      "reading 638 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.]\n",
      "time=0.03199934959411621\n",
      "Setting GB_goal to 0.1446951289176941 GB\n",
      "Starting '_read_with_standardizing'\n",
      "reading 790 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.]\n",
      "time=0.033997297286987305\n",
      "Setting GB_goal to 0.1446951289176941 GB\n",
      "Starting '_read_with_standardizing'\n",
      "reading 901 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.03 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.]\n",
      "time=0.02399921417236328\n",
      "Setting GB_goal to 0.1446951289176941 GB\n",
      "Starting '_read_with_standardizing'\n",
      "reading 956 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.]\n",
      "time=0.01900005340576172\n",
      "PhenotypeName\tpheno0\n",
      "SampleSize\t500\n",
      "SNPCount\t1000\n",
      "Runtime\t0.703998327255249\n",
      "Setting GB_goal to 0.1446951289176941 GB\n",
      "Starting '_read_with_standardizing'\n",
      "reading 715 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.]\n",
      "Starting '_read_with_standardizing'\n",
      "reading 715 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.]\n",
      "cmk\n",
      "time=0.04900336265563965\n",
      "Setting GB_goal to 0.1446951289176941 GB\n",
      "Starting '_read_with_standardizing'\n",
      "reading 638 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.04 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.]\n",
      "Starting '_read_with_standardizing'\n",
      "reading 638 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.]\n",
      "cmk\n",
      "time=0.05700087547302246\n",
      "Setting GB_goal to 0.1446951289176941 GB\n",
      "Starting '_read_with_standardizing'\n",
      "reading 790 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.]\n",
      "Starting '_read_with_standardizing'\n",
      "reading 790 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.]\n",
      "cmk\n",
      "time=0.04500079154968262\n",
      "Setting GB_goal to 0.1446951289176941 GB\n",
      "Starting '_read_with_standardizing'\n",
      "reading 901 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.]\n",
      "Starting '_read_with_standardizing'\n",
      "reading 901 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.]\n",
      "cmk\n",
      "time=0.04900026321411133\n",
      "Setting GB_goal to 0.1446951289176941 GB\n",
      "Starting '_read_with_standardizing'\n",
      "reading 956 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.03 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.]\n",
      "Starting '_read_with_standardizing'\n",
      "reading 956 SNPs in blocks of 500 and adding up kernels (for 500 individuals) with numpy.\n",
      "0.02 seconds elapsed\n",
      "Ending '_read_with_standardizing'\n",
      "Starting findH2\n",
      "h2=[0.]\n",
      "cmk\n",
      "time=0.0319976806640625\n",
      "PhenotypeName\tpheno2a\n",
      "SampleSize\t500\n",
      "SNPCount\t1000\n",
      "Runtime\t1.2920653820037842\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"TestSingleSnpLeaveOutOneChrom test_multipheno\")\n",
    "test_snps = Bed(bedbase, count_A1=False)\n",
    "print(test_snps.shape)\n",
    "pheno = phen_fn\n",
    "covar = cov_fn\n",
    "\n",
    "pheno2 = Pheno(pheno).read()\n",
    "pheno2.val[0,0] = 100\n",
    "pheno2.val[1,0] = -100\n",
    "\n",
    "if True:\n",
    "    pheno12 = SnpData(iid=pheno2.iid,sid=[\"pheno1\",\"pheno2\"],val = np.c_[Pheno(pheno).read().val,pheno2.val])\n",
    "    output_file = file_name(\"multipheno12\")\n",
    "    frame = single_snp(test_snps[:,::10], pheno12,\n",
    "                        force_full_rank=True,\n",
    "                                covar=covar,\n",
    "                                output_file_name=output_file,count_A1=False\n",
    "                                )\n",
    "    frame1 = frame[frame['Pheno']=='pheno1']\n",
    "    del frame1['Pheno']\n",
    "    compare_files(frame1,\"two_looc\")\n",
    "\n",
    "    frame2 = frame[frame['Pheno']=='pheno2']\n",
    "    del frame2['Pheno']\n",
    "    compare_files(frame2,\"multipheno2\")\n",
    "\n",
    "\n",
    "if True:\n",
    "    pheno11 = SnpData(iid=pheno2.iid,sid=[\"pheno1a\",\"pheno1b\"],val = np.c_[Pheno(pheno).read().val,Pheno(pheno).read().val])\n",
    "    output_file = file_name(\"multipheno11\")\n",
    "    frame = single_snp(test_snps[:,::10], pheno11,\n",
    "                        force_full_rank=True,\n",
    "                                covar=covar,\n",
    "                                output_file_name=output_file,count_A1=False\n",
    "                                )\n",
    "\n",
    "    frame1 = frame[frame['Pheno']=='pheno1a']\n",
    "    del frame1['Pheno']\n",
    "    compare_files(frame1,\"two_looc\")\n",
    "\n",
    "    frame2 = frame[frame['Pheno']=='pheno1b']\n",
    "    del frame2['Pheno']\n",
    "    compare_files(frame2,\"two_looc\")\n",
    "\n",
    "\n",
    "if True:\n",
    "    output_file = file_name(\"multipheno1\")\n",
    "    frame = single_snp(test_snps[:,::10], pheno,\n",
    "                        force_full_rank=True,\n",
    "                                covar=covar,\n",
    "                                output_file_name=output_file,count_A1=False\n",
    "                                )\n",
    "\n",
    "    compare_files(frame,\"two_looc\")\n",
    "\n",
    "\n",
    "if True:\n",
    "    output_file = file_name(\"multipheno2\")\n",
    "    frame = single_snp(test_snps[:,::10], pheno2,\n",
    "                        force_full_rank=True,\n",
    "                                covar=covar,\n",
    "                                output_file_name=output_file,count_A1=False\n",
    "                                )\n",
    "\n",
    "    compare_files(frame,\"multipheno2\")\n",
    "\n",
    "\n",
    "\n",
    "if True:\n",
    "    pheno22 = SnpData(iid=pheno2.iid,sid=[\"pheno2a\",\"pheno2b\"],val = np.c_[pheno2.val, pheno2.val])\n",
    "    output_file = file_name(\"multipheno22\")\n",
    "    frame = single_snp(test_snps[:,::10], pheno22,\n",
    "                        force_full_rank=True,\n",
    "                                covar=covar,\n",
    "                                output_file_name=output_file,count_A1=False\n",
    "                                )\n",
    "    frame1 = frame[frame['Pheno']=='pheno2a']\n",
    "    del frame1['Pheno']\n",
    "    compare_files(frame1,\"multipheno2\")\n",
    "\n",
    "    frame2 = frame[frame['Pheno']=='pheno2b']\n",
    "    del frame2['Pheno']\n",
    "    compare_files(frame2,\"multipheno2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SnpData(pheno_dup(3))"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "def pheno_dup(y_count):\n",
    "    pheno0 = Pheno(phen_fn).read()\n",
    "    iid = pheno0.iid\n",
    "    sid = [f\"sid{0}\" for sid_index in range(y_count)]\n",
    "    val = np.repeat(pheno0.val,y_count,axis=1)\n",
    "    snpdata = SnpData(iid=iid,sid=sid,val=val,name=f\"pheno_dup({y_count})\")\n",
    "    return snpdata\n",
    "\n",
    "pheno_dup(3)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PhenotypeName\tsid0\n",
      "SampleSize\t500\n",
      "SNPCount\t10000\n",
      "Runtime\t7.224602699279785\n",
      "Wall time: 7.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_count = 1\n",
    "runner = LocalMultiProc(10)\n",
    "\n",
    "frame = single_snp(test_snps[:,::1], pheno_dup(y_count),\n",
    "                    force_full_rank=True,\n",
    "                            covar=covar,\n",
    "                            runner=runner\n",
    "                            )\n",
    "\n",
    "# compare_files(frame,\"two_looc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}